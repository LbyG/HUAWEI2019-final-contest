{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lbyg/anaconda3/envs/pytorch/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'深': 0, '秦': 1, '京': 2, '海': 3, '成': 4, '南': 5, '杭': 6, '苏': 7, '松': 8}\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from pretrainedmodels.models import bninception\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt # plt 用于显示图片\n",
    "import matplotlib.image as mpimg # mpimg 用于读取图片\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "from preprocess import *\n",
    "\n",
    "img_w, img_h = 64, 64\n",
    "random_seed = 4050\n",
    "config_batch_size = 4\n",
    "class_n = (9 + 10 + 26)\n",
    "output_n = 9\n",
    "num_epochs = 100\n",
    "feature_extract = True\n",
    "use_pretrained=True\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "char_to_index = {\"深\":0, \"秦\":1, \"京\":2, \"海\":3, \"成\":4, \"南\":5, \"杭\":6, \"苏\":7, \"松\":8}\n",
    "print(char_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CarIdDataset(Dataset):\n",
    "    def __init__(self, data_list, mode, weight = 229, height = 229):\n",
    "        self.data_list = data_list\n",
    "        self.mode =mode\n",
    "        self.weight = weight\n",
    "        self.height = height\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        img_path, label = self.data_list[index][\"image_path\"], self.data_list[index][\"label\"]\n",
    "        img = np.array(Image.open(img_path))\n",
    "        \n",
    "        h, w, _ = img.shape\n",
    "        M = cv2.getAffineTransform(self.data_list[index][\"pts\"][0], self.data_list[index][\"pts\"][1])\n",
    "        img_dst = cv2.warpAffine(img, M, (w, h))\n",
    "        \n",
    "        #print(\"================================\")\n",
    "        char_img_list = []\n",
    "        for [x, y] in self.data_list[index][\"char_segmentation\"]:\n",
    "            char_img = cv2.resize(img_dst[:, x:y, :], (img_w, img_h), interpolation=cv2.INTER_CUBIC)\n",
    "            augment_img = iaa.SomeOf(2, [\n",
    "                iaa.Affine(rotate=(-30, 30), shear=(-16, 16), translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)}),\n",
    "                iaa.GaussianBlur(sigma=(0.0, 3.0)),\n",
    "                iaa.AdditiveGaussianNoise(scale=0.5*255),\n",
    "                iaa.Add((-40, 40), per_channel=0.5),\n",
    "                iaa.Sharpen(alpha=0.5),\n",
    "                iaa.CropAndPad(percent=(-0.25, 0.25)),\n",
    "            ])\n",
    "            if self.mode == \"train\":\n",
    "                char_img = augment_img.augment_image(char_img)\n",
    "            char_img = transforms.Compose([transforms.ToPILImage(), transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])(char_img)\n",
    "            #print(\"type(char_img) = \", type(char_img))\n",
    "            #print(\"char_img.shape = \", char_img.shape)\n",
    "            char_img_list.append(char_img)\n",
    "        img = torch.stack(char_img_list,0)\n",
    "        #img = torch.cat(inputs=char_img_list, dimension=0)\n",
    "        #print(\"img.shape = \", img.shape)\n",
    "        \n",
    "        #img = cv2.resize(img,(self.weight, self.height))\n",
    "        img = transforms.Compose([])(img)\n",
    "        #print(img.shape)\n",
    "        y = np.zeros((output_n, class_n))\n",
    "        for i in range(len(label)):\n",
    "            y[i, label[i]] = 1\n",
    "        \n",
    "        return img, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_file = \"./data/train-data-label.txt\"\n",
    "image_file = \"./data/train-data\"\n",
    "model_file = \"./model\"\n",
    "data_list = []\n",
    "with open(label_file, 'r') as file_to_read:\n",
    "    while True:\n",
    "        lines = file_to_read.readline().strip() # 整行读取数据\n",
    "        if not lines:\n",
    "            break\n",
    "        lines = lines.split(\",  \")\n",
    "        image_path = os.path.join(image_file, lines[1])\n",
    "        label = [];\n",
    "        label.append(char_to_index[lines[0][0]])\n",
    "        for i in range(1, len(lines[0])):\n",
    "            if '0' <= lines[0][i] and lines[0][i] <= '9':\n",
    "                label.append(9 + ord(lines[0][i]) - ord('0'))\n",
    "            else:\n",
    "                label.append(9 + 10 + ord(lines[0][i]) - ord('A'))\n",
    "        data_list.append({\"image_path\": image_path, \"label\":label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                inputs = torch.cat([inputs[i] for i in range(inputs.shape[0])], 0)\n",
    "                labels = torch.cat([labels[i] for i in range(labels.shape[0])], 0)\n",
    "                #print(\"type(inputs) = \", type(inputs))\n",
    "                #print(\"type(labels) = \", type(labels))\n",
    "                #print(\"inputs.shape = \", inputs.shape)\n",
    "                #print(\"labels.shape = \", labels.shape)\n",
    "                \n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    outputs = model(inputs).double()\n",
    "                    outputs = outputs.squeeze()\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    _, y = torch.max(labels, 1)\n",
    "                    #print(\"preds = \", preds)\n",
    "                    #print(\"labels = \", labels)\n",
    "                    running_corrects += torch.sum(preds == y)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                #running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            #print(len(dataloaders[phase].dataset))\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                model_filename = model_file + os.sep + str(epoch) + \"checkpoint.pth.tar\"\n",
    "                torch.save({\"state_dict\":best_model_wts}, model_filename)\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "            model_filename = model_file + os.sep + \"last_checkpoint.pth.tar\"\n",
    "            torch.save({\"state_dict\":model.state_dict()}, model_filename)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    best_model_filename = model_file + os.sep + \"best_checkpoint.pth.tar\"\n",
    "    torch.save({\"state_dict\":best_model_wts}, best_model_filename)\n",
    "    final_model_filename = model_file + os.sep + \"final_checkpoint.pth.tar\"\n",
    "    torch.save({\"state_dict\":model.state_dict()}, final_model_filename)\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor count in range(len(data_list)):\\n    data = data_list[count]\\n    print(\"count = \", count, \"data = \", data)\\n    pts1, pts2, char_segmentation = preprocess(data[\"image_path\"])\\n    data[\"pts\"] = [pts1, pts2]\\n    data[\"char_segmentation\"] = char_segmentation\\n    \\n    data_pkl_path = data[\"image_path\"].replace(\"jpg\", \"pkl\").replace(\"train-data\", \"preprocess\")\\n    output = open(data_pkl_path, \\'wb\\')\\n    pickle.dump(data, output)\\n    output.close()\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data_list = data_list[:100]\n",
    "\"\"\"\n",
    "for count in range(len(data_list)):\n",
    "    data = data_list[count]\n",
    "    print(\"count = \", count, \"data = \", data)\n",
    "    pts1, pts2, char_segmentation = preprocess(data[\"image_path\"])\n",
    "    data[\"pts\"] = [pts1, pts2]\n",
    "    data[\"char_segmentation\"] = char_segmentation\n",
    "    \n",
    "    data_pkl_path = data[\"image_path\"].replace(\"jpg\", \"pkl\").replace(\"train-data\", \"preprocess\")\n",
    "    output = open(data_pkl_path, 'wb')\n",
    "    pickle.dump(data, output)\n",
    "    output.close()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import pickle\n",
    "\n",
    "preprocess_data_list = []\n",
    "for data in data_list:\n",
    "    data_pkl_path = data[\"image_path\"].replace(\"jpg\", \"pkl\").replace(\"train-data\", \"preprocess\")\n",
    "    pkl_file = open(data_pkl_path, 'rb')\n",
    "    pkl_data = pickle.load(pkl_file)\n",
    "    preprocess_data_list.append(pkl_data)\n",
    "\n",
    "output = open('./data.pkl', 'wb')\n",
    "pickle.dump(preprocess_data_list, output)\n",
    "output.close()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "for data in data_list:\n",
    "    flag = 0\n",
    "    for [x, y] in data[\"char_segmentation\"]:\n",
    "        if x == y:\n",
    "            flag = 1\n",
    "    if flag == 1:\n",
    "        print(data[\"char_segmentation\"])\n",
    "        pts1, pts2, char_segmentation = preprocess(data[\"image_path\"])\n",
    "        data[\"pts\"] = [pts1, pts2]\n",
    "        data[\"char_segmentation\"] = char_segmentation\n",
    "        print(data[\"char_segmentation\"])\n",
    "output = open('./data.pkl', 'wb')\n",
    "pickle.dump(data_list, output)\n",
    "output.close()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "pkl_file = open('./data.pkl', 'rb')\n",
    "\n",
    "data_list = pickle.load(pkl_file)\n",
    "print(len(data_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_batch_size = 32\n",
    "train_data_list, val_data_list, _, _ = train_test_split(data_list, data_list, test_size=0.2, random_state=random_seed)\n",
    "train_gen = CarIdDataset(train_data_list, \"train\")\n",
    "train_loader = DataLoader(train_gen,batch_size=config_batch_size,shuffle=True,pin_memory=True,num_workers=2)\n",
    "\n",
    "val_gen = CarIdDataset(val_data_list, \"val\")\n",
    "val_loader = DataLoader(val_gen,batch_size=config_batch_size,shuffle=False,pin_memory=True,num_workers=2)\n",
    "dataloaders_dict = {\"train\":train_loader, \"val\":val_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.feature = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2)),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "            torch.nn.Conv2d(64, 192, kernel_size=(5, 5), stride=(2, 2), padding=(1, 1)),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "            torch.nn.Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "        )\n",
    "        self.classify = nn.Sequential(\n",
    "                nn.BatchNorm1d(256),\n",
    "                nn.Dropout(0.5),\n",
    "                nn.Linear(256, 45),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature(x)\n",
    "        adaptiveAvgPoolWidth = x.shape[2]\n",
    "        x = F.avg_pool2d(x, kernel_size=adaptiveAvgPoolWidth)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classify(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/199\n",
      "----------\n",
      "train Loss: 0.6021 Acc: 5.0056\n",
      "val Loss: 0.4234 Acc: 7.3413\n",
      "\n",
      "Epoch 1/199\n",
      "----------\n",
      "train Loss: 0.6025 Acc: 5.0084\n",
      "val Loss: 0.4270 Acc: 7.3575\n",
      "\n",
      "Epoch 2/199\n",
      "----------\n",
      "train Loss: 0.6001 Acc: 5.0497\n",
      "val Loss: 0.4244 Acc: 7.3500\n",
      "\n",
      "Epoch 3/199\n",
      "----------\n",
      "train Loss: 0.5993 Acc: 5.0350\n",
      "val Loss: 0.4214 Acc: 7.3662\n",
      "\n",
      "Epoch 4/199\n",
      "----------\n",
      "train Loss: 0.5986 Acc: 5.0312\n",
      "val Loss: 0.4167 Acc: 7.3563\n",
      "\n",
      "Epoch 5/199\n",
      "----------\n",
      "train Loss: 0.5987 Acc: 5.0356\n",
      "val Loss: 0.4184 Acc: 7.3813\n",
      "\n",
      "Epoch 6/199\n",
      "----------\n",
      "train Loss: 0.5964 Acc: 5.0294\n",
      "val Loss: 0.4172 Acc: 7.3700\n",
      "\n",
      "Epoch 7/199\n",
      "----------\n",
      "train Loss: 0.5953 Acc: 5.0600\n",
      "val Loss: 0.4183 Acc: 7.3875\n",
      "\n",
      "Epoch 8/199\n",
      "----------\n",
      "train Loss: 0.5951 Acc: 5.0906\n",
      "val Loss: 0.4166 Acc: 7.3925\n",
      "\n",
      "Epoch 9/199\n",
      "----------\n",
      "train Loss: 0.5932 Acc: 5.0784\n",
      "val Loss: 0.4122 Acc: 7.3700\n",
      "\n",
      "Epoch 10/199\n",
      "----------\n",
      "train Loss: 0.5913 Acc: 5.0812\n",
      "val Loss: 0.4091 Acc: 7.3975\n",
      "\n",
      "Epoch 11/199\n",
      "----------\n",
      "train Loss: 0.5912 Acc: 5.1053\n",
      "val Loss: 0.4123 Acc: 7.4038\n",
      "\n",
      "Epoch 12/199\n",
      "----------\n",
      "train Loss: 0.5906 Acc: 5.1037\n",
      "val Loss: 0.4066 Acc: 7.4138\n",
      "\n",
      "Epoch 13/199\n",
      "----------\n",
      "train Loss: 0.5885 Acc: 5.1419\n",
      "val Loss: 0.4104 Acc: 7.4150\n",
      "\n",
      "Epoch 14/199\n",
      "----------\n",
      "train Loss: 0.5900 Acc: 5.0906\n",
      "val Loss: 0.4081 Acc: 7.4125\n",
      "\n",
      "Epoch 15/199\n",
      "----------\n",
      "train Loss: 0.5863 Acc: 5.1516\n",
      "val Loss: 0.4074 Acc: 7.4188\n",
      "\n",
      "Epoch 16/199\n",
      "----------\n",
      "train Loss: 0.5860 Acc: 5.1503\n",
      "val Loss: 0.4049 Acc: 7.4350\n",
      "\n",
      "Epoch 17/199\n",
      "----------\n",
      "train Loss: 0.5859 Acc: 5.1641\n",
      "val Loss: 0.4063 Acc: 7.4363\n",
      "\n",
      "Epoch 18/199\n",
      "----------\n",
      "train Loss: 0.5843 Acc: 5.1553\n",
      "val Loss: 0.4014 Acc: 7.4450\n",
      "\n",
      "Epoch 19/199\n",
      "----------\n",
      "train Loss: 0.5817 Acc: 5.1866\n",
      "val Loss: 0.4015 Acc: 7.4475\n",
      "\n",
      "Epoch 20/199\n",
      "----------\n",
      "train Loss: 0.5832 Acc: 5.1628\n",
      "val Loss: 0.3989 Acc: 7.4512\n",
      "\n",
      "Epoch 21/199\n",
      "----------\n",
      "train Loss: 0.5812 Acc: 5.1784\n",
      "val Loss: 0.3995 Acc: 7.4675\n",
      "\n",
      "Epoch 22/199\n",
      "----------\n",
      "train Loss: 0.5803 Acc: 5.1994\n",
      "val Loss: 0.3969 Acc: 7.4875\n",
      "\n",
      "Epoch 23/199\n",
      "----------\n",
      "train Loss: 0.5785 Acc: 5.2019\n",
      "val Loss: 0.3950 Acc: 7.4863\n",
      "\n",
      "Epoch 24/199\n",
      "----------\n",
      "train Loss: 0.5796 Acc: 5.2228\n",
      "val Loss: 0.3980 Acc: 7.4775\n",
      "\n",
      "Epoch 25/199\n",
      "----------\n",
      "train Loss: 0.5764 Acc: 5.2453\n",
      "val Loss: 0.3955 Acc: 7.4925\n",
      "\n",
      "Epoch 26/199\n",
      "----------\n",
      "train Loss: 0.5746 Acc: 5.2378\n",
      "val Loss: 0.3929 Acc: 7.4638\n",
      "\n",
      "Epoch 27/199\n",
      "----------\n",
      "train Loss: 0.5736 Acc: 5.2547\n",
      "val Loss: 0.3940 Acc: 7.4875\n",
      "\n",
      "Epoch 28/199\n",
      "----------\n",
      "train Loss: 0.5730 Acc: 5.2825\n",
      "val Loss: 0.3922 Acc: 7.5113\n",
      "\n",
      "Epoch 29/199\n",
      "----------\n",
      "train Loss: 0.5742 Acc: 5.2316\n",
      "val Loss: 0.3907 Acc: 7.5012\n",
      "\n",
      "Epoch 30/199\n",
      "----------\n",
      "train Loss: 0.5739 Acc: 5.2250\n",
      "val Loss: 0.3889 Acc: 7.5263\n",
      "\n",
      "Epoch 31/199\n",
      "----------\n",
      "train Loss: 0.5716 Acc: 5.2481\n",
      "val Loss: 0.3877 Acc: 7.5063\n",
      "\n",
      "Epoch 32/199\n",
      "----------\n",
      "train Loss: 0.5700 Acc: 5.2750\n",
      "val Loss: 0.3832 Acc: 7.5338\n",
      "\n",
      "Epoch 33/199\n",
      "----------\n",
      "train Loss: 0.5683 Acc: 5.2891\n",
      "val Loss: 0.3838 Acc: 7.5350\n",
      "\n",
      "Epoch 34/199\n",
      "----------\n",
      "train Loss: 0.5685 Acc: 5.2928\n",
      "val Loss: 0.3861 Acc: 7.5312\n",
      "\n",
      "Epoch 35/199\n",
      "----------\n",
      "train Loss: 0.5675 Acc: 5.2956\n",
      "val Loss: 0.3858 Acc: 7.5312\n",
      "\n",
      "Epoch 36/199\n",
      "----------\n",
      "train Loss: 0.5669 Acc: 5.3003\n",
      "val Loss: 0.3812 Acc: 7.5625\n",
      "\n",
      "Epoch 37/199\n",
      "----------\n",
      "train Loss: 0.5657 Acc: 5.3078\n",
      "val Loss: 0.3806 Acc: 7.5637\n",
      "\n",
      "Epoch 38/199\n",
      "----------\n",
      "train Loss: 0.5654 Acc: 5.3031\n",
      "val Loss: 0.3797 Acc: 7.5475\n",
      "\n",
      "Epoch 39/199\n",
      "----------\n",
      "train Loss: 0.5644 Acc: 5.3375\n",
      "val Loss: 0.3827 Acc: 7.5688\n",
      "\n",
      "Epoch 40/199\n",
      "----------\n",
      "train Loss: 0.5622 Acc: 5.3406\n",
      "val Loss: 0.3766 Acc: 7.5550\n",
      "\n",
      "Epoch 41/199\n",
      "----------\n",
      "train Loss: 0.5614 Acc: 5.3747\n",
      "val Loss: 0.3768 Acc: 7.5775\n",
      "\n",
      "Epoch 42/199\n",
      "----------\n",
      "train Loss: 0.5613 Acc: 5.3416\n",
      "val Loss: 0.3757 Acc: 7.5625\n",
      "\n",
      "Epoch 43/199\n",
      "----------\n",
      "train Loss: 0.5604 Acc: 5.3506\n",
      "val Loss: 0.3763 Acc: 7.5950\n",
      "\n",
      "Epoch 44/199\n",
      "----------\n",
      "train Loss: 0.5586 Acc: 5.3356\n",
      "val Loss: 0.3704 Acc: 7.5925\n",
      "\n",
      "Epoch 45/199\n",
      "----------\n",
      "train Loss: 0.5589 Acc: 5.3503\n",
      "val Loss: 0.3732 Acc: 7.5850\n",
      "\n",
      "Epoch 46/199\n",
      "----------\n",
      "train Loss: 0.5569 Acc: 5.3772\n",
      "val Loss: 0.3681 Acc: 7.5938\n",
      "\n",
      "Epoch 47/199\n",
      "----------\n",
      "train Loss: 0.5568 Acc: 5.3813\n",
      "val Loss: 0.3708 Acc: 7.6075\n",
      "\n",
      "Epoch 48/199\n",
      "----------\n",
      "train Loss: 0.5554 Acc: 5.3925\n",
      "val Loss: 0.3689 Acc: 7.6063\n",
      "\n",
      "Epoch 49/199\n",
      "----------\n",
      "train Loss: 0.5545 Acc: 5.3594\n",
      "val Loss: 0.3714 Acc: 7.6000\n",
      "\n",
      "Epoch 50/199\n",
      "----------\n",
      "train Loss: 0.5559 Acc: 5.3425\n",
      "val Loss: 0.3686 Acc: 7.6113\n",
      "\n",
      "Epoch 51/199\n",
      "----------\n",
      "train Loss: 0.5536 Acc: 5.4219\n",
      "val Loss: 0.3700 Acc: 7.6288\n",
      "\n",
      "Epoch 52/199\n",
      "----------\n",
      "train Loss: 0.5534 Acc: 5.4025\n",
      "val Loss: 0.3669 Acc: 7.6200\n",
      "\n",
      "Epoch 53/199\n",
      "----------\n",
      "train Loss: 0.5509 Acc: 5.4387\n",
      "val Loss: 0.3642 Acc: 7.6238\n",
      "\n",
      "Epoch 54/199\n",
      "----------\n",
      "train Loss: 0.5522 Acc: 5.4438\n",
      "val Loss: 0.3646 Acc: 7.6212\n",
      "\n",
      "Epoch 55/199\n",
      "----------\n",
      "train Loss: 0.5497 Acc: 5.4278\n",
      "val Loss: 0.3676 Acc: 7.6350\n",
      "\n",
      "Epoch 56/199\n",
      "----------\n",
      "train Loss: 0.5492 Acc: 5.4503\n",
      "val Loss: 0.3631 Acc: 7.6387\n",
      "\n",
      "Epoch 57/199\n",
      "----------\n",
      "train Loss: 0.5493 Acc: 5.4297\n",
      "val Loss: 0.3624 Acc: 7.6425\n",
      "\n",
      "Epoch 58/199\n",
      "----------\n",
      "train Loss: 0.5467 Acc: 5.4553\n",
      "val Loss: 0.3631 Acc: 7.6487\n",
      "\n",
      "Epoch 59/199\n",
      "----------\n",
      "train Loss: 0.5479 Acc: 5.4481\n",
      "val Loss: 0.3581 Acc: 7.6600\n",
      "\n",
      "Epoch 60/199\n",
      "----------\n",
      "train Loss: 0.5450 Acc: 5.4906\n",
      "val Loss: 0.3596 Acc: 7.6625\n",
      "\n",
      "Epoch 61/199\n",
      "----------\n",
      "train Loss: 0.5454 Acc: 5.4644\n",
      "val Loss: 0.3564 Acc: 7.6437\n",
      "\n",
      "Epoch 62/199\n",
      "----------\n",
      "train Loss: 0.5448 Acc: 5.4678\n",
      "val Loss: 0.3573 Acc: 7.6975\n",
      "\n",
      "Epoch 63/199\n",
      "----------\n",
      "train Loss: 0.5430 Acc: 5.5388\n",
      "val Loss: 0.3544 Acc: 7.6562\n",
      "\n",
      "Epoch 64/199\n",
      "----------\n",
      "train Loss: 0.5427 Acc: 5.4756\n",
      "val Loss: 0.3520 Acc: 7.6725\n",
      "\n",
      "Epoch 65/199\n",
      "----------\n",
      "train Loss: 0.5412 Acc: 5.5056\n",
      "val Loss: 0.3531 Acc: 7.6887\n",
      "\n",
      "Epoch 66/199\n",
      "----------\n",
      "train Loss: 0.5399 Acc: 5.5431\n",
      "val Loss: 0.3499 Acc: 7.6800\n",
      "\n",
      "Epoch 67/199\n",
      "----------\n",
      "train Loss: 0.5389 Acc: 5.5334\n",
      "val Loss: 0.3507 Acc: 7.6950\n",
      "\n",
      "Epoch 68/199\n",
      "----------\n",
      "train Loss: 0.5381 Acc: 5.5469\n",
      "val Loss: 0.3529 Acc: 7.6825\n",
      "\n",
      "Epoch 69/199\n",
      "----------\n",
      "train Loss: 0.5374 Acc: 5.5528\n",
      "val Loss: 0.3491 Acc: 7.6938\n",
      "\n",
      "Epoch 70/199\n",
      "----------\n",
      "train Loss: 0.5366 Acc: 5.5328\n",
      "val Loss: 0.3489 Acc: 7.6975\n",
      "\n",
      "Epoch 71/199\n",
      "----------\n",
      "train Loss: 0.5365 Acc: 5.5688\n",
      "val Loss: 0.3493 Acc: 7.7125\n",
      "\n",
      "Epoch 72/199\n",
      "----------\n",
      "train Loss: 0.5358 Acc: 5.5269\n",
      "val Loss: 0.3491 Acc: 7.7150\n",
      "\n",
      "Epoch 73/199\n",
      "----------\n",
      "train Loss: 0.5363 Acc: 5.5359\n",
      "val Loss: 0.3456 Acc: 7.7188\n",
      "\n",
      "Epoch 74/199\n",
      "----------\n",
      "train Loss: 0.5338 Acc: 5.5619\n",
      "val Loss: 0.3474 Acc: 7.7163\n",
      "\n",
      "Epoch 75/199\n",
      "----------\n",
      "train Loss: 0.5342 Acc: 5.5541\n",
      "val Loss: 0.3452 Acc: 7.7025\n",
      "\n",
      "Epoch 76/199\n",
      "----------\n",
      "train Loss: 0.5323 Acc: 5.5637\n",
      "val Loss: 0.3449 Acc: 7.7100\n",
      "\n",
      "Epoch 77/199\n",
      "----------\n",
      "train Loss: 0.5323 Acc: 5.5531\n",
      "val Loss: 0.3443 Acc: 7.7263\n",
      "\n",
      "Epoch 78/199\n",
      "----------\n",
      "train Loss: 0.5308 Acc: 5.5925\n",
      "val Loss: 0.3420 Acc: 7.7050\n",
      "\n",
      "Epoch 79/199\n",
      "----------\n",
      "train Loss: 0.5289 Acc: 5.6212\n",
      "val Loss: 0.3428 Acc: 7.7425\n",
      "\n",
      "Epoch 80/199\n",
      "----------\n",
      "train Loss: 0.5281 Acc: 5.6103\n",
      "val Loss: 0.3412 Acc: 7.7237\n",
      "\n",
      "Epoch 81/199\n",
      "----------\n",
      "train Loss: 0.5278 Acc: 5.6075\n",
      "val Loss: 0.3397 Acc: 7.7388\n",
      "\n",
      "Epoch 82/199\n",
      "----------\n",
      "train Loss: 0.5273 Acc: 5.6159\n",
      "val Loss: 0.3412 Acc: 7.7375\n",
      "\n",
      "Epoch 83/199\n",
      "----------\n",
      "train Loss: 0.5261 Acc: 5.6228\n",
      "val Loss: 0.3371 Acc: 7.7450\n",
      "\n",
      "Epoch 84/199\n",
      "----------\n",
      "train Loss: 0.5260 Acc: 5.6084\n",
      "val Loss: 0.3358 Acc: 7.7412\n",
      "\n",
      "Epoch 85/199\n",
      "----------\n",
      "train Loss: 0.5268 Acc: 5.6212\n",
      "val Loss: 0.3386 Acc: 7.7475\n",
      "\n",
      "Epoch 86/199\n",
      "----------\n",
      "train Loss: 0.5253 Acc: 5.6003\n",
      "val Loss: 0.3353 Acc: 7.7588\n",
      "\n",
      "Epoch 87/199\n",
      "----------\n",
      "train Loss: 0.5232 Acc: 5.6494\n",
      "val Loss: 0.3373 Acc: 7.7438\n",
      "\n",
      "Epoch 88/199\n",
      "----------\n",
      "train Loss: 0.5244 Acc: 5.6378\n",
      "val Loss: 0.3337 Acc: 7.7462\n",
      "\n",
      "Epoch 89/199\n",
      "----------\n",
      "train Loss: 0.5228 Acc: 5.6503\n",
      "val Loss: 0.3324 Acc: 7.7650\n",
      "\n",
      "Epoch 90/199\n",
      "----------\n",
      "train Loss: 0.5228 Acc: 5.6469\n",
      "val Loss: 0.3307 Acc: 7.7763\n",
      "\n",
      "Epoch 91/199\n",
      "----------\n",
      "train Loss: 0.5218 Acc: 5.6669\n",
      "val Loss: 0.3320 Acc: 7.7663\n",
      "\n",
      "Epoch 92/199\n",
      "----------\n",
      "train Loss: 0.5208 Acc: 5.6850\n",
      "val Loss: 0.3280 Acc: 7.7800\n",
      "\n",
      "Epoch 93/199\n",
      "----------\n",
      "train Loss: 0.5185 Acc: 5.6928\n",
      "val Loss: 0.3308 Acc: 7.7800\n",
      "\n",
      "Epoch 94/199\n",
      "----------\n",
      "train Loss: 0.5165 Acc: 5.6903\n",
      "val Loss: 0.3252 Acc: 7.7788\n",
      "\n",
      "Epoch 95/199\n",
      "----------\n",
      "train Loss: 0.5177 Acc: 5.6791\n",
      "val Loss: 0.3304 Acc: 7.7775\n",
      "\n",
      "Epoch 96/199\n",
      "----------\n",
      "train Loss: 0.5168 Acc: 5.6825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.3267 Acc: 7.7800\n",
      "\n",
      "Epoch 97/199\n",
      "----------\n",
      "train Loss: 0.5146 Acc: 5.7241\n",
      "val Loss: 0.3292 Acc: 7.8013\n",
      "\n",
      "Epoch 98/199\n",
      "----------\n",
      "train Loss: 0.5141 Acc: 5.7194\n",
      "val Loss: 0.3232 Acc: 7.7825\n",
      "\n",
      "Epoch 99/199\n",
      "----------\n",
      "train Loss: 0.5146 Acc: 5.7266\n",
      "val Loss: 0.3267 Acc: 7.7875\n",
      "\n",
      "Epoch 100/199\n",
      "----------\n",
      "train Loss: 0.5128 Acc: 5.7344\n",
      "val Loss: 0.3258 Acc: 7.7888\n",
      "\n",
      "Epoch 101/199\n",
      "----------\n",
      "train Loss: 0.5130 Acc: 5.7053\n",
      "val Loss: 0.3246 Acc: 7.7862\n",
      "\n",
      "Epoch 102/199\n",
      "----------\n",
      "train Loss: 0.5126 Acc: 5.7281\n",
      "val Loss: 0.3243 Acc: 7.7938\n",
      "\n",
      "Epoch 103/199\n",
      "----------\n",
      "train Loss: 0.5109 Acc: 5.7694\n",
      "val Loss: 0.3247 Acc: 7.7925\n",
      "\n",
      "Epoch 104/199\n",
      "----------\n",
      "train Loss: 0.5086 Acc: 5.7525\n",
      "val Loss: 0.3220 Acc: 7.7963\n",
      "\n",
      "Epoch 105/199\n",
      "----------\n",
      "train Loss: 0.5115 Acc: 5.7438\n",
      "val Loss: 0.3218 Acc: 7.7975\n",
      "\n",
      "Epoch 106/199\n",
      "----------\n",
      "train Loss: 0.5104 Acc: 5.7366\n",
      "val Loss: 0.3187 Acc: 7.8025\n",
      "\n",
      "Epoch 107/199\n",
      "----------\n",
      "train Loss: 0.5078 Acc: 5.7737\n",
      "val Loss: 0.3208 Acc: 7.8150\n",
      "\n",
      "Epoch 108/199\n",
      "----------\n",
      "train Loss: 0.5067 Acc: 5.7584\n",
      "val Loss: 0.3178 Acc: 7.8163\n",
      "\n",
      "Epoch 109/199\n",
      "----------\n",
      "train Loss: 0.5077 Acc: 5.7594\n",
      "val Loss: 0.3198 Acc: 7.8125\n",
      "\n",
      "Epoch 110/199\n",
      "----------\n",
      "train Loss: 0.5057 Acc: 5.7781\n",
      "val Loss: 0.3189 Acc: 7.8188\n",
      "\n",
      "Epoch 111/199\n",
      "----------\n",
      "train Loss: 0.5061 Acc: 5.7309\n",
      "val Loss: 0.3155 Acc: 7.8100\n",
      "\n",
      "Epoch 112/199\n",
      "----------\n",
      "train Loss: 0.5052 Acc: 5.7969\n",
      "val Loss: 0.3162 Acc: 7.8262\n",
      "\n",
      "Epoch 113/199\n",
      "----------\n",
      "train Loss: 0.5038 Acc: 5.8206\n",
      "val Loss: 0.3143 Acc: 7.8225\n",
      "\n",
      "Epoch 114/199\n",
      "----------\n",
      "train Loss: 0.5033 Acc: 5.8013\n",
      "val Loss: 0.3112 Acc: 7.8213\n",
      "\n",
      "Epoch 115/199\n",
      "----------\n",
      "train Loss: 0.5027 Acc: 5.8063\n",
      "val Loss: 0.3132 Acc: 7.8288\n",
      "\n",
      "Epoch 116/199\n",
      "----------\n",
      "train Loss: 0.5027 Acc: 5.8238\n",
      "val Loss: 0.3093 Acc: 7.8363\n",
      "\n",
      "Epoch 117/199\n",
      "----------\n",
      "train Loss: 0.5023 Acc: 5.7919\n",
      "val Loss: 0.3103 Acc: 7.8325\n",
      "\n",
      "Epoch 118/199\n",
      "----------\n",
      "train Loss: 0.5001 Acc: 5.8253\n",
      "val Loss: 0.3090 Acc: 7.8312\n",
      "\n",
      "Epoch 119/199\n",
      "----------\n",
      "train Loss: 0.5000 Acc: 5.8094\n",
      "val Loss: 0.3115 Acc: 7.8487\n",
      "\n",
      "Epoch 120/199\n",
      "----------\n",
      "train Loss: 0.5001 Acc: 5.8069\n",
      "val Loss: 0.3084 Acc: 7.8425\n",
      "\n",
      "Epoch 121/199\n",
      "----------\n",
      "train Loss: 0.4986 Acc: 5.8303\n",
      "val Loss: 0.3080 Acc: 7.8413\n",
      "\n",
      "Epoch 122/199\n",
      "----------\n",
      "train Loss: 0.4990 Acc: 5.8113\n",
      "val Loss: 0.3050 Acc: 7.8475\n",
      "\n",
      "Epoch 123/199\n",
      "----------\n",
      "train Loss: 0.4989 Acc: 5.8241\n",
      "val Loss: 0.3061 Acc: 7.8575\n",
      "\n",
      "Epoch 124/199\n",
      "----------\n",
      "train Loss: 0.4965 Acc: 5.8531\n",
      "val Loss: 0.3033 Acc: 7.8575\n",
      "\n",
      "Epoch 125/199\n",
      "----------\n",
      "train Loss: 0.4956 Acc: 5.8772\n",
      "val Loss: 0.3044 Acc: 7.8425\n",
      "\n",
      "Epoch 126/199\n",
      "----------\n",
      "train Loss: 0.4969 Acc: 5.8463\n",
      "val Loss: 0.3077 Acc: 7.8675\n",
      "\n",
      "Epoch 127/199\n",
      "----------\n",
      "train Loss: 0.4941 Acc: 5.8819\n",
      "val Loss: 0.3056 Acc: 7.8638\n",
      "\n",
      "Epoch 128/199\n",
      "----------\n",
      "train Loss: 0.4934 Acc: 5.8716\n",
      "val Loss: 0.3045 Acc: 7.8575\n",
      "\n",
      "Epoch 129/199\n",
      "----------\n",
      "train Loss: 0.4938 Acc: 5.8419\n",
      "val Loss: 0.3029 Acc: 7.8600\n",
      "\n",
      "Epoch 130/199\n",
      "----------\n",
      "train Loss: 0.4922 Acc: 5.8769\n",
      "val Loss: 0.3008 Acc: 7.8600\n",
      "\n",
      "Epoch 131/199\n",
      "----------\n",
      "train Loss: 0.4920 Acc: 5.9028\n",
      "val Loss: 0.3021 Acc: 7.8500\n",
      "\n",
      "Epoch 132/199\n",
      "----------\n",
      "train Loss: 0.4930 Acc: 5.8722\n",
      "val Loss: 0.3007 Acc: 7.8675\n",
      "\n",
      "Epoch 133/199\n",
      "----------\n",
      "train Loss: 0.4912 Acc: 5.9034\n",
      "val Loss: 0.3012 Acc: 7.8725\n",
      "\n",
      "Epoch 134/199\n",
      "----------\n",
      "train Loss: 0.4893 Acc: 5.9097\n",
      "val Loss: 0.3016 Acc: 7.8675\n",
      "\n",
      "Epoch 135/199\n",
      "----------\n",
      "train Loss: 0.4899 Acc: 5.8991\n",
      "val Loss: 0.2998 Acc: 7.8800\n",
      "\n",
      "Epoch 136/199\n",
      "----------\n",
      "train Loss: 0.4889 Acc: 5.9069\n",
      "val Loss: 0.2967 Acc: 7.8838\n",
      "\n",
      "Epoch 137/199\n",
      "----------\n",
      "train Loss: 0.4887 Acc: 5.9056\n",
      "val Loss: 0.2965 Acc: 7.8850\n",
      "\n",
      "Epoch 138/199\n",
      "----------\n",
      "train Loss: 0.4888 Acc: 5.8841\n",
      "val Loss: 0.2975 Acc: 7.8950\n",
      "\n",
      "Epoch 139/199\n",
      "----------\n",
      "train Loss: 0.4868 Acc: 5.9250\n",
      "val Loss: 0.2969 Acc: 7.8750\n",
      "\n",
      "Epoch 140/199\n",
      "----------\n",
      "train Loss: 0.4864 Acc: 5.9222\n",
      "val Loss: 0.2997 Acc: 7.8963\n",
      "\n",
      "Epoch 141/199\n",
      "----------\n",
      "train Loss: 0.4847 Acc: 5.9184\n",
      "val Loss: 0.2948 Acc: 7.8750\n",
      "\n",
      "Epoch 142/199\n",
      "----------\n",
      "train Loss: 0.4845 Acc: 5.9575\n",
      "val Loss: 0.2976 Acc: 7.8850\n",
      "\n",
      "Epoch 143/199\n",
      "----------\n",
      "train Loss: 0.4845 Acc: 5.9387\n",
      "val Loss: 0.2927 Acc: 7.8887\n",
      "\n",
      "Epoch 144/199\n",
      "----------\n",
      "train Loss: 0.4825 Acc: 5.9650\n",
      "val Loss: 0.2931 Acc: 7.8900\n",
      "\n",
      "Epoch 145/199\n",
      "----------\n",
      "train Loss: 0.4845 Acc: 5.9431\n",
      "val Loss: 0.2923 Acc: 7.8863\n",
      "\n",
      "Epoch 146/199\n",
      "----------\n",
      "train Loss: 0.4839 Acc: 5.9387\n",
      "val Loss: 0.2936 Acc: 7.8963\n",
      "\n",
      "Epoch 147/199\n",
      "----------\n",
      "train Loss: 0.4828 Acc: 5.9425\n",
      "val Loss: 0.2937 Acc: 7.9000\n",
      "\n",
      "Epoch 148/199\n",
      "----------\n",
      "train Loss: 0.4821 Acc: 5.9269\n",
      "val Loss: 0.2934 Acc: 7.9038\n",
      "\n",
      "Epoch 149/199\n",
      "----------\n",
      "train Loss: 0.4819 Acc: 5.9359\n",
      "val Loss: 0.2891 Acc: 7.8913\n",
      "\n",
      "Epoch 150/199\n",
      "----------\n",
      "train Loss: 0.4802 Acc: 5.9475\n",
      "val Loss: 0.2911 Acc: 7.9112\n",
      "\n",
      "Epoch 151/199\n",
      "----------\n",
      "train Loss: 0.4797 Acc: 5.9925\n",
      "val Loss: 0.2896 Acc: 7.9062\n",
      "\n",
      "Epoch 152/199\n",
      "----------\n",
      "train Loss: 0.4780 Acc: 5.9959\n",
      "val Loss: 0.2908 Acc: 7.9050\n",
      "\n",
      "Epoch 153/199\n",
      "----------\n",
      "train Loss: 0.4781 Acc: 5.9875\n",
      "val Loss: 0.2861 Acc: 7.9138\n",
      "\n",
      "Epoch 154/199\n",
      "----------\n",
      "train Loss: 0.4764 Acc: 5.9997\n",
      "val Loss: 0.2892 Acc: 7.9075\n",
      "\n",
      "Epoch 155/199\n",
      "----------\n",
      "train Loss: 0.4767 Acc: 5.9931\n",
      "val Loss: 0.2887 Acc: 7.9038\n",
      "\n",
      "Epoch 156/199\n",
      "----------\n",
      "train Loss: 0.4771 Acc: 5.9747\n",
      "val Loss: 0.2862 Acc: 7.9238\n",
      "\n",
      "Epoch 157/199\n",
      "----------\n",
      "train Loss: 0.4757 Acc: 6.0144\n",
      "val Loss: 0.2862 Acc: 7.9075\n",
      "\n",
      "Epoch 158/199\n",
      "----------\n",
      "train Loss: 0.4757 Acc: 5.9984\n",
      "val Loss: 0.2821 Acc: 7.9162\n",
      "\n",
      "Epoch 159/199\n",
      "----------\n",
      "train Loss: 0.4748 Acc: 6.0447\n",
      "val Loss: 0.2850 Acc: 7.9287\n",
      "\n",
      "Epoch 160/199\n",
      "----------\n",
      "train Loss: 0.4738 Acc: 6.0016\n",
      "val Loss: 0.2833 Acc: 7.9300\n",
      "\n",
      "Epoch 161/199\n",
      "----------\n",
      "train Loss: 0.4721 Acc: 6.0216\n",
      "val Loss: 0.2861 Acc: 7.9287\n",
      "\n",
      "Epoch 162/199\n",
      "----------\n",
      "train Loss: 0.4728 Acc: 6.0263\n",
      "val Loss: 0.2836 Acc: 7.9250\n",
      "\n",
      "Epoch 163/199\n",
      "----------\n",
      "train Loss: 0.4728 Acc: 6.0250\n",
      "val Loss: 0.2818 Acc: 7.9325\n",
      "\n",
      "Epoch 164/199\n",
      "----------\n",
      "train Loss: 0.4719 Acc: 6.0422\n",
      "val Loss: 0.2786 Acc: 7.9425\n",
      "\n",
      "Epoch 165/199\n",
      "----------\n",
      "train Loss: 0.4711 Acc: 6.0225\n",
      "val Loss: 0.2796 Acc: 7.9325\n",
      "\n",
      "Epoch 166/199\n",
      "----------\n",
      "train Loss: 0.4695 Acc: 6.0828\n",
      "val Loss: 0.2823 Acc: 7.9387\n",
      "\n",
      "Epoch 167/199\n",
      "----------\n",
      "train Loss: 0.4709 Acc: 6.0334\n",
      "val Loss: 0.2807 Acc: 7.9400\n",
      "\n",
      "Epoch 168/199\n",
      "----------\n",
      "train Loss: 0.4687 Acc: 6.0634\n",
      "val Loss: 0.2810 Acc: 7.9500\n",
      "\n",
      "Epoch 169/199\n",
      "----------\n",
      "train Loss: 0.4686 Acc: 6.0541\n",
      "val Loss: 0.2788 Acc: 7.9488\n",
      "\n",
      "Epoch 170/199\n",
      "----------\n",
      "train Loss: 0.4670 Acc: 6.0806\n",
      "val Loss: 0.2793 Acc: 7.9500\n",
      "\n",
      "Epoch 171/199\n",
      "----------\n",
      "train Loss: 0.4678 Acc: 6.0625\n",
      "val Loss: 0.2786 Acc: 7.9425\n",
      "\n",
      "Epoch 172/199\n",
      "----------\n",
      "train Loss: 0.4659 Acc: 6.1013\n",
      "val Loss: 0.2771 Acc: 7.9325\n",
      "\n",
      "Epoch 173/199\n",
      "----------\n",
      "train Loss: 0.4662 Acc: 6.0544\n",
      "val Loss: 0.2778 Acc: 7.9475\n",
      "\n",
      "Epoch 174/199\n",
      "----------\n",
      "train Loss: 0.4650 Acc: 6.0563\n",
      "val Loss: 0.2784 Acc: 7.9387\n",
      "\n",
      "Epoch 175/199\n",
      "----------\n",
      "train Loss: 0.4649 Acc: 6.0744\n",
      "val Loss: 0.2767 Acc: 7.9400\n",
      "\n",
      "Epoch 176/199\n",
      "----------\n",
      "train Loss: 0.4634 Acc: 6.1191\n",
      "val Loss: 0.2715 Acc: 7.9475\n",
      "\n",
      "Epoch 177/199\n",
      "----------\n",
      "train Loss: 0.4627 Acc: 6.1266\n",
      "val Loss: 0.2738 Acc: 7.9463\n",
      "\n",
      "Epoch 178/199\n",
      "----------\n",
      "train Loss: 0.4634 Acc: 6.1028\n",
      "val Loss: 0.2752 Acc: 7.9488\n",
      "\n",
      "Epoch 179/199\n",
      "----------\n",
      "train Loss: 0.4626 Acc: 6.1022\n",
      "val Loss: 0.2735 Acc: 7.9538\n",
      "\n",
      "Epoch 180/199\n",
      "----------\n",
      "train Loss: 0.4616 Acc: 6.1241\n",
      "val Loss: 0.2725 Acc: 7.9575\n",
      "\n",
      "Epoch 181/199\n",
      "----------\n",
      "train Loss: 0.4619 Acc: 6.0978\n",
      "val Loss: 0.2699 Acc: 7.9625\n",
      "\n",
      "Epoch 182/199\n",
      "----------\n",
      "train Loss: 0.4609 Acc: 6.1322\n",
      "val Loss: 0.2716 Acc: 7.9638\n",
      "\n",
      "Epoch 183/199\n",
      "----------\n",
      "train Loss: 0.4614 Acc: 6.1056\n",
      "val Loss: 0.2727 Acc: 7.9638\n",
      "\n",
      "Epoch 184/199\n",
      "----------\n",
      "train Loss: 0.4603 Acc: 6.1116\n",
      "val Loss: 0.2696 Acc: 7.9688\n",
      "\n",
      "Epoch 185/199\n",
      "----------\n",
      "train Loss: 0.4584 Acc: 6.1037\n",
      "val Loss: 0.2690 Acc: 7.9600\n",
      "\n",
      "Epoch 186/199\n",
      "----------\n",
      "train Loss: 0.4579 Acc: 6.1256\n",
      "val Loss: 0.2685 Acc: 7.9675\n",
      "\n",
      "Epoch 187/199\n",
      "----------\n",
      "train Loss: 0.4590 Acc: 6.1250\n",
      "val Loss: 0.2680 Acc: 7.9737\n",
      "\n",
      "Epoch 188/199\n",
      "----------\n",
      "train Loss: 0.4571 Acc: 6.1275\n",
      "val Loss: 0.2690 Acc: 7.9663\n",
      "\n",
      "Epoch 189/199\n",
      "----------\n",
      "train Loss: 0.4580 Acc: 6.1403\n",
      "val Loss: 0.2691 Acc: 7.9750\n",
      "\n",
      "Epoch 190/199\n",
      "----------\n",
      "train Loss: 0.4576 Acc: 6.1225\n",
      "val Loss: 0.2676 Acc: 7.9825\n",
      "\n",
      "Epoch 191/199\n",
      "----------\n",
      "train Loss: 0.4557 Acc: 6.1534\n",
      "val Loss: 0.2705 Acc: 7.9763\n",
      "\n",
      "Epoch 192/199\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.4547 Acc: 6.1794\n",
      "val Loss: 0.2659 Acc: 7.9725\n",
      "\n",
      "Epoch 193/199\n",
      "----------\n",
      "train Loss: 0.4541 Acc: 6.1681\n",
      "val Loss: 0.2661 Acc: 7.9787\n",
      "\n",
      "Epoch 194/199\n",
      "----------\n",
      "train Loss: 0.4544 Acc: 6.1634\n",
      "val Loss: 0.2648 Acc: 7.9850\n",
      "\n",
      "Epoch 195/199\n",
      "----------\n",
      "train Loss: 0.4543 Acc: 6.1541\n",
      "val Loss: 0.2649 Acc: 7.9725\n",
      "\n",
      "Epoch 196/199\n",
      "----------\n",
      "train Loss: 0.4536 Acc: 6.1584\n",
      "val Loss: 0.2633 Acc: 7.9800\n",
      "\n",
      "Epoch 197/199\n",
      "----------\n",
      "train Loss: 0.4513 Acc: 6.1791\n",
      "val Loss: 0.2640 Acc: 7.9850\n",
      "\n",
      "Epoch 198/199\n",
      "----------\n",
      "train Loss: 0.4531 Acc: 6.1531\n",
      "val Loss: 0.2637 Acc: 7.9787\n",
      "\n",
      "Epoch 199/199\n",
      "----------\n",
      "train Loss: 0.4509 Acc: 6.1919\n",
      "val Loss: 0.2637 Acc: 7.9725\n",
      "\n",
      "Training complete in 62m 25s\n",
      "Best val Acc: 7.985000\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "set_parameter_requires_grad(model_ft, feature_extract)\n",
    "num_ftrs = model_ft.classifier[6].in_features\n",
    "model_ft.classifier[6] = nn.Linear(num_ftrs,class_n)\n",
    "model_ft.to(device)\n",
    "print(model_ft)\n",
    "model_ft = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2)),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "    torch.nn.Conv2d(64, 192, kernel_size=(5, 5), stride=(2, 2), padding=(1, 1)),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "    torch.nn.Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "    torch.nn.Dropout(p=0.5),\n",
    "    torch.nn.Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0)),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(128, class_n, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0)),\n",
    ")\n",
    "\"\"\"\n",
    "model_ft = Net()\n",
    "last_model_filename = model_file + os.sep + \"last_checkpoint.pth.tar\"\n",
    "last_model = torch.load(last_model_filename)\n",
    "model_ft.load_state_dict(last_model[\"state_dict\"])\n",
    "model_ft.to(device)\n",
    "\n",
    "params_to_update = model_ft.parameters()\n",
    "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "\n",
    "model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "torch.Size([2, 2, 3])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.zeros(2, 3)\n",
    "print(a)\n",
    "b = torch.zeros(2, 3)\n",
    "print(b)\n",
    "c = torch.stack((a,b),0)\n",
    "print(c.shape)\n",
    "print(c[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
