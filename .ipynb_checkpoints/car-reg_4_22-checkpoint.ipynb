{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lbyg/anaconda3/envs/pytorch/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'深': 0, '秦': 1, '京': 2, '海': 3, '成': 4, '南': 5, '杭': 6, '苏': 7, '松': 8}\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from pretrainedmodels.models import bninception\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt # plt 用于显示图片\n",
    "import matplotlib.image as mpimg # mpimg 用于读取图片\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "from preprocess import *\n",
    "\n",
    "img_w, img_h = 64, 64\n",
    "random_seed = 4050\n",
    "config_batch_size = 4\n",
    "class_n = (9 + 10 + 26)\n",
    "output_n = 9\n",
    "num_epochs = 100\n",
    "feature_extract = True\n",
    "use_pretrained=True\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "char_to_index = {\"深\":0, \"秦\":1, \"京\":2, \"海\":3, \"成\":4, \"南\":5, \"杭\":6, \"苏\":7, \"松\":8}\n",
    "print(char_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CarIdDataset(Dataset):\n",
    "    def __init__(self, data_list, mode, weight = 229, height = 229):\n",
    "        self.data_list = data_list\n",
    "        self.mode =mode\n",
    "        self.weight = weight\n",
    "        self.height = height\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self,index):\n",
    "        img_path, label = self.data_list[index][\"image_path\"], self.data_list[index][\"label\"]\n",
    "        img = np.array(Image.open(img_path))\n",
    "        \n",
    "        h, w, _ = img.shape\n",
    "        M = cv2.getAffineTransform(self.data_list[index][\"pts\"][0], self.data_list[index][\"pts\"][1])\n",
    "        img_dst = cv2.warpAffine(img, M, (w, h))\n",
    "        \n",
    "        #print(\"================================\")\n",
    "        char_img_list = []\n",
    "        for [x, y] in self.data_list[index][\"char_segmentation\"]:\n",
    "            char_img = cv2.resize(img_dst[:, x:y, :], (img_w, img_h), interpolation=cv2.INTER_CUBIC)\n",
    "            augment_img = iaa.SomeOf(2, [\n",
    "                iaa.Affine(rotate=(-30, 30), shear=(-16, 16), translate_percent={\"x\": (-0.2, 0.2), \"y\": (-0.2, 0.2)}),\n",
    "                iaa.GaussianBlur(sigma=(0.0, 3.0)),\n",
    "                iaa.AdditiveGaussianNoise(scale=0.5*255),\n",
    "                iaa.Add((-40, 40), per_channel=0.5),\n",
    "                iaa.Sharpen(alpha=0.5),\n",
    "                iaa.CropAndPad(percent=(-0.25, 0.25)),\n",
    "            ])\n",
    "            if self.mode == \"train\":\n",
    "                char_img = augment_img.augment_image(char_img)\n",
    "            char_img = transforms.Compose([transforms.ToPILImage(), transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])(char_img)\n",
    "            #print(\"type(char_img) = \", type(char_img))\n",
    "            #print(\"char_img.shape = \", char_img.shape)\n",
    "            char_img_list.append(char_img)\n",
    "        img = torch.stack(char_img_list,0)\n",
    "        #img = torch.cat(inputs=char_img_list, dimension=0)\n",
    "        #print(\"img.shape = \", img.shape)\n",
    "        \n",
    "        #img = cv2.resize(img,(self.weight, self.height))\n",
    "        img = transforms.Compose([])(img)\n",
    "        #print(img.shape)\n",
    "        y = np.zeros((output_n, class_n))\n",
    "        for i in range(len(label)):\n",
    "            y[i, label[i]] = 1\n",
    "        \n",
    "        return img, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_file = \"./data/train-data-label.txt\"\n",
    "image_file = \"./data/train-data\"\n",
    "model_file = \"./model\"\n",
    "data_list = []\n",
    "with open(label_file, 'r') as file_to_read:\n",
    "    while True:\n",
    "        lines = file_to_read.readline().strip() # 整行读取数据\n",
    "        if not lines:\n",
    "            break\n",
    "        lines = lines.split(\",  \")\n",
    "        image_path = os.path.join(image_file, lines[1])\n",
    "        label = [];\n",
    "        label.append(char_to_index[lines[0][0]])\n",
    "        for i in range(1, len(lines[0])):\n",
    "            if '0' <= lines[0][i] and lines[0][i] <= '9':\n",
    "                label.append(9 + ord(lines[0][i]) - ord('0'))\n",
    "            else:\n",
    "                label.append(9 + 10 + ord(lines[0][i]) - ord('A'))\n",
    "        data_list.append({\"image_path\": image_path, \"label\":label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                inputs = torch.cat([inputs[i] for i in range(inputs.shape[0])], 0)\n",
    "                labels = torch.cat([labels[i] for i in range(labels.shape[0])], 0)\n",
    "                #print(\"type(inputs) = \", type(inputs))\n",
    "                #print(\"type(labels) = \", type(labels))\n",
    "                #print(\"inputs.shape = \", inputs.shape)\n",
    "                #print(\"labels.shape = \", labels.shape)\n",
    "                \n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "                    # Special case for inception because in training it has an auxiliary output. In train\n",
    "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
    "                    #   but in testing we only consider the final output.\n",
    "                    outputs = model(inputs).double()\n",
    "                    outputs = outputs.squeeze()\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    _, y = torch.max(labels, 1)\n",
    "                    #print(\"preds = \", preds)\n",
    "                    #print(\"labels = \", labels)\n",
    "                    running_corrects += torch.sum(preds == y)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                #running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            #print(len(dataloaders[phase].dataset))\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                model_filename = model_file + os.sep + str(epoch) + \"checkpoint.pth.tar\"\n",
    "                torch.save({\"state_dict\":best_model_wts}, model_filename)\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "            model_filename = model_file + os.sep + \"last_checkpoint.pth.tar\"\n",
    "            torch.save({\"state_dict\":model.state_dict()}, model_filename)\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    best_model_filename = model_file + os.sep + \"best_checkpoint.pth.tar\"\n",
    "    torch.save({\"state_dict\":best_model_wts}, best_model_filename)\n",
    "    final_model_filename = model_file + os.sep + \"final_checkpoint.pth.tar\"\n",
    "    torch.save({\"state_dict\":model.state_dict()}, final_model_filename)\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor count in range(len(data_list)):\\n    data = data_list[count]\\n    print(\"count = \", count, \"data = \", data)\\n    pts1, pts2, char_segmentation = preprocess(data[\"image_path\"])\\n    data[\"pts\"] = [pts1, pts2]\\n    data[\"char_segmentation\"] = char_segmentation\\n    \\n    data_pkl_path = data[\"image_path\"].replace(\"jpg\", \"pkl\").replace(\"train-data\", \"preprocess\")\\n    output = open(data_pkl_path, \\'wb\\')\\n    pickle.dump(data, output)\\n    output.close()\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data_list = data_list[:100]\n",
    "\"\"\"\n",
    "for count in range(len(data_list)):\n",
    "    data = data_list[count]\n",
    "    print(\"count = \", count, \"data = \", data)\n",
    "    pts1, pts2, char_segmentation = preprocess(data[\"image_path\"])\n",
    "    data[\"pts\"] = [pts1, pts2]\n",
    "    data[\"char_segmentation\"] = char_segmentation\n",
    "    \n",
    "    data_pkl_path = data[\"image_path\"].replace(\"jpg\", \"pkl\").replace(\"train-data\", \"preprocess\")\n",
    "    output = open(data_pkl_path, 'wb')\n",
    "    pickle.dump(data, output)\n",
    "    output.close()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "import pickle\n",
    "\n",
    "preprocess_data_list = []\n",
    "for data in data_list:\n",
    "    data_pkl_path = data[\"image_path\"].replace(\"jpg\", \"pkl\").replace(\"train-data\", \"preprocess\")\n",
    "    pkl_file = open(data_pkl_path, 'rb')\n",
    "    pkl_data = pickle.load(pkl_file)\n",
    "    preprocess_data_list.append(pkl_data)\n",
    "\n",
    "output = open('./data.pkl', 'wb')\n",
    "pickle.dump(preprocess_data_list, output)\n",
    "output.close()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "for data in data_list:\n",
    "    flag = 0\n",
    "    for [x, y] in data[\"char_segmentation\"]:\n",
    "        if x == y:\n",
    "            flag = 1\n",
    "    if flag == 1:\n",
    "        print(data[\"char_segmentation\"])\n",
    "        pts1, pts2, char_segmentation = preprocess(data[\"image_path\"])\n",
    "        data[\"pts\"] = [pts1, pts2]\n",
    "        data[\"char_segmentation\"] = char_segmentation\n",
    "        print(data[\"char_segmentation\"])\n",
    "output = open('./data.pkl', 'wb')\n",
    "pickle.dump(data_list, output)\n",
    "output.close()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "pkl_file = open('./data.pkl', 'rb')\n",
    "\n",
    "data_list = pickle.load(pkl_file)\n",
    "print(len(data_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_batch_size = 32\n",
    "train_data_list, val_data_list, _, _ = train_test_split(data_list, data_list, test_size=0.2, random_state=random_seed)\n",
    "train_gen = CarIdDataset(train_data_list, \"train\")\n",
    "train_loader = DataLoader(train_gen,batch_size=config_batch_size,shuffle=True,pin_memory=True,num_workers=2)\n",
    "\n",
    "val_gen = CarIdDataset(val_data_list, \"val\")\n",
    "val_loader = DataLoader(val_gen,batch_size=config_batch_size,shuffle=False,pin_memory=True,num_workers=2)\n",
    "dataloaders_dict = {\"train\":train_loader, \"val\":val_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.feature = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2)),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "            torch.nn.Conv2d(64, 192, kernel_size=(5, 5), stride=(2, 2), padding=(1, 1)),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "            torch.nn.Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "        )\n",
    "        self.classify = nn.Sequential(\n",
    "                nn.BatchNorm1d(256),\n",
    "                nn.Dropout(0.5),\n",
    "                nn.Linear(256, 45),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature(x)\n",
    "        adaptiveAvgPoolWidth = x.shape[2]\n",
    "        x = F.avg_pool2d(x, kernel_size=adaptiveAvgPoolWidth)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classify(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/99\n",
      "----------\n",
      "train Loss: 0.7328 Acc: 3.7950\n",
      "val Loss: 0.5914 Acc: 6.3887\n",
      "\n",
      "Epoch 1/99\n",
      "----------\n",
      "train Loss: 0.7316 Acc: 3.8428\n",
      "val Loss: 0.5891 Acc: 6.3813\n",
      "\n",
      "Epoch 2/99\n",
      "----------\n",
      "train Loss: 0.7292 Acc: 3.8584\n",
      "val Loss: 0.5891 Acc: 6.4025\n",
      "\n",
      "Epoch 3/99\n",
      "----------\n",
      "train Loss: 0.7284 Acc: 3.8544\n",
      "val Loss: 0.5880 Acc: 6.4038\n",
      "\n",
      "Epoch 4/99\n",
      "----------\n",
      "train Loss: 0.7267 Acc: 3.8225\n",
      "val Loss: 0.5842 Acc: 6.4363\n",
      "\n",
      "Epoch 5/99\n",
      "----------\n",
      "train Loss: 0.7263 Acc: 3.8350\n",
      "val Loss: 0.5819 Acc: 6.4525\n",
      "\n",
      "Epoch 6/99\n",
      "----------\n",
      "train Loss: 0.7231 Acc: 3.9047\n",
      "val Loss: 0.5783 Acc: 6.5038\n",
      "\n",
      "Epoch 7/99\n",
      "----------\n",
      "train Loss: 0.7220 Acc: 3.9178\n",
      "val Loss: 0.5747 Acc: 6.5063\n",
      "\n",
      "Epoch 8/99\n",
      "----------\n",
      "train Loss: 0.7199 Acc: 3.9184\n",
      "val Loss: 0.5747 Acc: 6.5312\n",
      "\n",
      "Epoch 9/99\n",
      "----------\n",
      "train Loss: 0.7192 Acc: 3.9403\n",
      "val Loss: 0.5704 Acc: 6.5088\n",
      "\n",
      "Epoch 10/99\n",
      "----------\n",
      "train Loss: 0.7180 Acc: 3.9563\n",
      "val Loss: 0.5702 Acc: 6.5425\n",
      "\n",
      "Epoch 11/99\n",
      "----------\n",
      "train Loss: 0.7157 Acc: 3.9863\n",
      "val Loss: 0.5725 Acc: 6.5412\n",
      "\n",
      "Epoch 12/99\n",
      "----------\n",
      "train Loss: 0.7148 Acc: 3.9681\n",
      "val Loss: 0.5650 Acc: 6.5650\n",
      "\n",
      "Epoch 13/99\n",
      "----------\n",
      "train Loss: 0.7121 Acc: 4.0000\n",
      "val Loss: 0.5665 Acc: 6.5987\n",
      "\n",
      "Epoch 14/99\n",
      "----------\n",
      "train Loss: 0.7122 Acc: 3.9972\n",
      "val Loss: 0.5575 Acc: 6.5812\n",
      "\n",
      "Epoch 15/99\n",
      "----------\n",
      "train Loss: 0.7101 Acc: 4.0025\n",
      "val Loss: 0.5569 Acc: 6.5938\n",
      "\n",
      "Epoch 16/99\n",
      "----------\n",
      "train Loss: 0.7085 Acc: 4.0353\n",
      "val Loss: 0.5602 Acc: 6.6050\n",
      "\n",
      "Epoch 17/99\n",
      "----------\n",
      "train Loss: 0.7061 Acc: 4.0703\n",
      "val Loss: 0.5530 Acc: 6.6325\n",
      "\n",
      "Epoch 18/99\n",
      "----------\n",
      "train Loss: 0.7057 Acc: 4.0716\n",
      "val Loss: 0.5543 Acc: 6.5788\n",
      "\n",
      "Epoch 19/99\n",
      "----------\n",
      "train Loss: 0.7040 Acc: 4.0644\n",
      "val Loss: 0.5502 Acc: 6.6425\n",
      "\n",
      "Epoch 20/99\n",
      "----------\n",
      "train Loss: 0.7013 Acc: 4.1166\n",
      "val Loss: 0.5528 Acc: 6.6387\n",
      "\n",
      "Epoch 21/99\n",
      "----------\n",
      "train Loss: 0.7010 Acc: 4.1194\n",
      "val Loss: 0.5453 Acc: 6.6738\n",
      "\n",
      "Epoch 22/99\n",
      "----------\n",
      "train Loss: 0.6992 Acc: 4.1425\n",
      "val Loss: 0.5516 Acc: 6.6425\n",
      "\n",
      "Epoch 23/99\n",
      "----------\n",
      "train Loss: 0.6977 Acc: 4.1787\n",
      "val Loss: 0.5463 Acc: 6.6675\n",
      "\n",
      "Epoch 24/99\n",
      "----------\n",
      "train Loss: 0.6966 Acc: 4.1653\n",
      "val Loss: 0.5401 Acc: 6.7000\n",
      "\n",
      "Epoch 25/99\n",
      "----------\n",
      "train Loss: 0.6944 Acc: 4.2100\n",
      "val Loss: 0.5396 Acc: 6.6813\n",
      "\n",
      "Epoch 26/99\n",
      "----------\n",
      "train Loss: 0.6939 Acc: 4.1769\n",
      "val Loss: 0.5360 Acc: 6.7275\n",
      "\n",
      "Epoch 27/99\n",
      "----------\n",
      "train Loss: 0.6916 Acc: 4.2316\n",
      "val Loss: 0.5339 Acc: 6.7563\n",
      "\n",
      "Epoch 28/99\n",
      "----------\n",
      "train Loss: 0.6904 Acc: 4.2438\n",
      "val Loss: 0.5369 Acc: 6.7650\n",
      "\n",
      "Epoch 29/99\n",
      "----------\n",
      "train Loss: 0.6897 Acc: 4.2363\n",
      "val Loss: 0.5356 Acc: 6.7750\n",
      "\n",
      "Epoch 30/99\n",
      "----------\n",
      "train Loss: 0.6866 Acc: 4.2422\n",
      "val Loss: 0.5289 Acc: 6.7713\n",
      "\n",
      "Epoch 31/99\n",
      "----------\n",
      "train Loss: 0.6856 Acc: 4.2459\n",
      "val Loss: 0.5312 Acc: 6.8050\n",
      "\n",
      "Epoch 32/99\n",
      "----------\n",
      "train Loss: 0.6854 Acc: 4.2647\n",
      "val Loss: 0.5245 Acc: 6.7825\n",
      "\n",
      "Epoch 33/99\n",
      "----------\n",
      "train Loss: 0.6833 Acc: 4.2853\n",
      "val Loss: 0.5255 Acc: 6.8100\n",
      "\n",
      "Epoch 34/99\n",
      "----------\n",
      "train Loss: 0.6830 Acc: 4.2944\n",
      "val Loss: 0.5248 Acc: 6.8325\n",
      "\n",
      "Epoch 35/99\n",
      "----------\n",
      "train Loss: 0.6819 Acc: 4.2991\n",
      "val Loss: 0.5248 Acc: 6.8225\n",
      "\n",
      "Epoch 36/99\n",
      "----------\n",
      "train Loss: 0.6796 Acc: 4.3247\n",
      "val Loss: 0.5224 Acc: 6.8125\n",
      "\n",
      "Epoch 37/99\n",
      "----------\n",
      "train Loss: 0.6774 Acc: 4.3503\n",
      "val Loss: 0.5183 Acc: 6.8575\n",
      "\n",
      "Epoch 38/99\n",
      "----------\n",
      "train Loss: 0.6759 Acc: 4.3531\n",
      "val Loss: 0.5143 Acc: 6.8475\n",
      "\n",
      "Epoch 39/99\n",
      "----------\n",
      "train Loss: 0.6761 Acc: 4.3453\n",
      "val Loss: 0.5164 Acc: 6.8388\n",
      "\n",
      "Epoch 40/99\n",
      "----------\n",
      "train Loss: 0.6748 Acc: 4.3384\n",
      "val Loss: 0.5124 Acc: 6.9162\n",
      "\n",
      "Epoch 41/99\n",
      "----------\n",
      "train Loss: 0.6734 Acc: 4.3600\n",
      "val Loss: 0.5133 Acc: 6.8900\n",
      "\n",
      "Epoch 42/99\n",
      "----------\n",
      "train Loss: 0.6718 Acc: 4.3887\n",
      "val Loss: 0.5119 Acc: 6.9300\n",
      "\n",
      "Epoch 43/99\n",
      "----------\n",
      "train Loss: 0.6686 Acc: 4.4156\n",
      "val Loss: 0.5026 Acc: 6.9387\n",
      "\n",
      "Epoch 44/99\n",
      "----------\n",
      "train Loss: 0.6686 Acc: 4.4250\n",
      "val Loss: 0.5056 Acc: 6.9475\n",
      "\n",
      "Epoch 45/99\n",
      "----------\n",
      "train Loss: 0.6676 Acc: 4.4234\n",
      "val Loss: 0.5050 Acc: 6.9475\n",
      "\n",
      "Epoch 46/99\n",
      "----------\n",
      "train Loss: 0.6664 Acc: 4.4516\n",
      "val Loss: 0.5009 Acc: 6.9488\n",
      "\n",
      "Epoch 47/99\n",
      "----------\n",
      "train Loss: 0.6655 Acc: 4.4112\n",
      "val Loss: 0.5012 Acc: 6.9675\n",
      "\n",
      "Epoch 48/99\n",
      "----------\n",
      "train Loss: 0.6640 Acc: 4.4847\n",
      "val Loss: 0.4969 Acc: 6.9787\n",
      "\n",
      "Epoch 49/99\n",
      "----------\n",
      "train Loss: 0.6621 Acc: 4.5031\n",
      "val Loss: 0.4998 Acc: 6.9888\n",
      "\n",
      "Epoch 50/99\n",
      "----------\n",
      "train Loss: 0.6606 Acc: 4.4850\n",
      "val Loss: 0.4961 Acc: 6.9888\n",
      "\n",
      "Epoch 51/99\n",
      "----------\n",
      "train Loss: 0.6591 Acc: 4.5163\n",
      "val Loss: 0.4941 Acc: 6.9950\n",
      "\n",
      "Epoch 52/99\n",
      "----------\n",
      "train Loss: 0.6582 Acc: 4.5156\n",
      "val Loss: 0.4901 Acc: 6.9900\n",
      "\n",
      "Epoch 53/99\n",
      "----------\n",
      "train Loss: 0.6570 Acc: 4.5247\n",
      "val Loss: 0.4891 Acc: 7.0362\n",
      "\n",
      "Epoch 54/99\n",
      "----------\n",
      "train Loss: 0.6564 Acc: 4.5194\n",
      "val Loss: 0.4915 Acc: 7.0300\n",
      "\n",
      "Epoch 55/99\n",
      "----------\n",
      "train Loss: 0.6553 Acc: 4.5312\n",
      "val Loss: 0.4882 Acc: 7.0163\n",
      "\n",
      "Epoch 56/99\n",
      "----------\n",
      "train Loss: 0.6530 Acc: 4.5431\n",
      "val Loss: 0.4895 Acc: 7.0350\n",
      "\n",
      "Epoch 57/99\n",
      "----------\n",
      "train Loss: 0.6528 Acc: 4.5691\n",
      "val Loss: 0.4869 Acc: 7.0263\n",
      "\n",
      "Epoch 58/99\n",
      "----------\n",
      "train Loss: 0.6515 Acc: 4.5750\n",
      "val Loss: 0.4806 Acc: 7.0412\n",
      "\n",
      "Epoch 59/99\n",
      "----------\n",
      "train Loss: 0.6493 Acc: 4.5878\n",
      "val Loss: 0.4820 Acc: 7.0762\n",
      "\n",
      "Epoch 60/99\n",
      "----------\n",
      "train Loss: 0.6485 Acc: 4.6028\n",
      "val Loss: 0.4806 Acc: 7.0600\n",
      "\n",
      "Epoch 61/99\n",
      "----------\n",
      "train Loss: 0.6475 Acc: 4.6100\n",
      "val Loss: 0.4733 Acc: 7.1113\n",
      "\n",
      "Epoch 62/99\n",
      "----------\n",
      "train Loss: 0.6461 Acc: 4.6341\n",
      "val Loss: 0.4783 Acc: 7.0788\n",
      "\n",
      "Epoch 63/99\n",
      "----------\n",
      "train Loss: 0.6452 Acc: 4.6334\n",
      "val Loss: 0.4692 Acc: 7.0738\n",
      "\n",
      "Epoch 64/99\n",
      "----------\n",
      "train Loss: 0.6439 Acc: 4.6228\n",
      "val Loss: 0.4763 Acc: 7.1025\n",
      "\n",
      "Epoch 65/99\n",
      "----------\n",
      "train Loss: 0.6418 Acc: 4.6641\n",
      "val Loss: 0.4764 Acc: 7.1262\n",
      "\n",
      "Epoch 66/99\n",
      "----------\n",
      "train Loss: 0.6394 Acc: 4.6725\n",
      "val Loss: 0.4686 Acc: 7.1138\n",
      "\n",
      "Epoch 67/99\n",
      "----------\n",
      "train Loss: 0.6406 Acc: 4.6562\n",
      "val Loss: 0.4716 Acc: 7.1338\n",
      "\n",
      "Epoch 68/99\n",
      "----------\n",
      "train Loss: 0.6388 Acc: 4.6866\n",
      "val Loss: 0.4699 Acc: 7.1212\n",
      "\n",
      "Epoch 69/99\n",
      "----------\n",
      "train Loss: 0.6370 Acc: 4.7034\n",
      "val Loss: 0.4672 Acc: 7.1300\n",
      "\n",
      "Epoch 70/99\n",
      "----------\n",
      "train Loss: 0.6352 Acc: 4.7444\n",
      "val Loss: 0.4663 Acc: 7.1162\n",
      "\n",
      "Epoch 71/99\n",
      "----------\n",
      "train Loss: 0.6356 Acc: 4.7216\n",
      "val Loss: 0.4666 Acc: 7.1475\n",
      "\n",
      "Epoch 72/99\n",
      "----------\n",
      "train Loss: 0.6339 Acc: 4.7469\n",
      "val Loss: 0.4632 Acc: 7.1688\n",
      "\n",
      "Epoch 73/99\n",
      "----------\n",
      "train Loss: 0.6329 Acc: 4.7647\n",
      "val Loss: 0.4608 Acc: 7.1513\n",
      "\n",
      "Epoch 74/99\n",
      "----------\n",
      "train Loss: 0.6307 Acc: 4.7816\n",
      "val Loss: 0.4611 Acc: 7.1688\n",
      "\n",
      "Epoch 75/99\n",
      "----------\n",
      "train Loss: 0.6291 Acc: 4.7687\n",
      "val Loss: 0.4587 Acc: 7.1875\n",
      "\n",
      "Epoch 76/99\n",
      "----------\n",
      "train Loss: 0.6295 Acc: 4.7566\n",
      "val Loss: 0.4578 Acc: 7.1775\n",
      "\n",
      "Epoch 77/99\n",
      "----------\n",
      "train Loss: 0.6276 Acc: 4.7747\n",
      "val Loss: 0.4543 Acc: 7.2050\n",
      "\n",
      "Epoch 78/99\n",
      "----------\n",
      "train Loss: 0.6273 Acc: 4.7922\n",
      "val Loss: 0.4544 Acc: 7.2038\n",
      "\n",
      "Epoch 79/99\n",
      "----------\n",
      "train Loss: 0.6251 Acc: 4.8050\n",
      "val Loss: 0.4512 Acc: 7.2062\n",
      "\n",
      "Epoch 80/99\n",
      "----------\n",
      "train Loss: 0.6227 Acc: 4.8541\n",
      "val Loss: 0.4535 Acc: 7.2188\n",
      "\n",
      "Epoch 81/99\n",
      "----------\n",
      "train Loss: 0.6236 Acc: 4.8097\n",
      "val Loss: 0.4497 Acc: 7.2138\n",
      "\n",
      "Epoch 82/99\n",
      "----------\n",
      "train Loss: 0.6227 Acc: 4.8388\n",
      "val Loss: 0.4504 Acc: 7.2425\n",
      "\n",
      "Epoch 83/99\n",
      "----------\n",
      "train Loss: 0.6198 Acc: 4.8447\n",
      "val Loss: 0.4474 Acc: 7.2512\n",
      "\n",
      "Epoch 84/99\n",
      "----------\n",
      "train Loss: 0.6206 Acc: 4.8481\n",
      "val Loss: 0.4456 Acc: 7.2438\n",
      "\n",
      "Epoch 85/99\n",
      "----------\n",
      "train Loss: 0.6185 Acc: 4.8584\n",
      "val Loss: 0.4419 Acc: 7.2525\n",
      "\n",
      "Epoch 86/99\n",
      "----------\n",
      "train Loss: 0.6186 Acc: 4.8569\n",
      "val Loss: 0.4416 Acc: 7.2600\n",
      "\n",
      "Epoch 87/99\n",
      "----------\n",
      "train Loss: 0.6166 Acc: 4.9025\n",
      "val Loss: 0.4414 Acc: 7.2700\n",
      "\n",
      "Epoch 88/99\n",
      "----------\n",
      "train Loss: 0.6147 Acc: 4.9122\n",
      "val Loss: 0.4380 Acc: 7.2838\n",
      "\n",
      "Epoch 89/99\n",
      "----------\n",
      "train Loss: 0.6143 Acc: 4.9250\n",
      "val Loss: 0.4395 Acc: 7.2737\n",
      "\n",
      "Epoch 90/99\n",
      "----------\n",
      "train Loss: 0.6133 Acc: 4.9072\n",
      "val Loss: 0.4366 Acc: 7.2975\n",
      "\n",
      "Epoch 91/99\n",
      "----------\n",
      "train Loss: 0.6129 Acc: 4.9056\n",
      "val Loss: 0.4373 Acc: 7.3125\n",
      "\n",
      "Epoch 92/99\n",
      "----------\n",
      "train Loss: 0.6110 Acc: 4.9459\n",
      "val Loss: 0.4404 Acc: 7.3025\n",
      "\n",
      "Epoch 93/99\n",
      "----------\n",
      "train Loss: 0.6103 Acc: 4.9394\n",
      "val Loss: 0.4344 Acc: 7.3000\n",
      "\n",
      "Epoch 94/99\n",
      "----------\n",
      "train Loss: 0.6087 Acc: 4.9612\n",
      "val Loss: 0.4317 Acc: 7.3050\n",
      "\n",
      "Epoch 95/99\n",
      "----------\n",
      "train Loss: 0.6097 Acc: 4.9178\n",
      "val Loss: 0.4282 Acc: 7.3188\n",
      "\n",
      "Epoch 96/99\n",
      "----------\n",
      "train Loss: 0.6071 Acc: 4.9866\n",
      "val Loss: 0.4315 Acc: 7.3150\n",
      "\n",
      "Epoch 97/99\n",
      "----------\n",
      "train Loss: 0.6049 Acc: 5.0059\n",
      "val Loss: 0.4294 Acc: 7.3213\n",
      "\n",
      "Epoch 98/99\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6048 Acc: 4.9634\n",
      "val Loss: 0.4248 Acc: 7.3200\n",
      "\n",
      "Epoch 99/99\n",
      "----------\n",
      "train Loss: 0.6045 Acc: 4.9753\n",
      "val Loss: 0.4267 Acc: 7.3238\n",
      "\n",
      "Training complete in 30m 29s\n",
      "Best val Acc: 7.323750\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "model_ft = models.alexnet(pretrained=use_pretrained)\n",
    "set_parameter_requires_grad(model_ft, feature_extract)\n",
    "num_ftrs = model_ft.classifier[6].in_features\n",
    "model_ft.classifier[6] = nn.Linear(num_ftrs,class_n)\n",
    "model_ft.to(device)\n",
    "print(model_ft)\n",
    "model_ft = torch.nn.Sequential(\n",
    "    torch.nn.Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(2, 2)),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "    torch.nn.Conv2d(64, 192, kernel_size=(5, 5), stride=(2, 2), padding=(1, 1)),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "    torch.nn.Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "    torch.nn.Dropout(p=0.5),\n",
    "    torch.nn.Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0)),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Conv2d(128, class_n, kernel_size=(1, 1), stride=(1, 1), padding=(0, 0)),\n",
    ")\n",
    "\"\"\"\n",
    "model_ft = Net()\n",
    "last_model_filename = model_file + os.sep + \"last_checkpoint.pth.tar\"\n",
    "last_model = torch.load(last_model_filename)\n",
    "model_ft.load_state_dict(last_model[\"state_dict\"])\n",
    "model_ft.to(device)\n",
    "\n",
    "params_to_update = model_ft.parameters()\n",
    "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n",
    "criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "\n",
    "model_ft, hist = train_model(model_ft, dataloaders_dict, criterion, optimizer_ft, num_epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "torch.Size([2, 2, 3])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.zeros(2, 3)\n",
    "print(a)\n",
    "b = torch.zeros(2, 3)\n",
    "print(b)\n",
    "c = torch.stack((a,b),0)\n",
    "print(c.shape)\n",
    "print(c[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
